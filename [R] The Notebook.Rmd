---
title: "[R] The Notebook"
author: "*Veneta Baeva*"  
output: github_document
---
![](/Users/venetabaeva/git/repository4/Picture1.jpg)
---

## Libraries

> library load 

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(dplyr)
```
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
```{r}
library(dslabs)
```
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(tidyverse)
```
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(rafalib)
```
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(UsingR)
```



## I.

1.[dataFrame] create

```{r}
dfTest <- data.frame(names=c("A","B","C","D"),
                     num1 = c(1,2,3,4),
                     num2 = c(10,20,30,40),
                     stringsAsFactors = FALSE)
dfTest
```

1.[data] read

```{r}
data(heights)
```

1.[file] read

```{r}
dfPonzo <- read.csv(
  file = ("/Users/venetabaeva/git/repository4/PonzoEyeTrack.csv"),
  header = TRUE,
  sep = ";",
  dec = ".")
```

1.[file] read

```{r}
dfAlc <- read.csv(
                      file = ("/Users/venetabaeva/git/repository4/gapminder.csv"),
                      header = TRUE,
                      sep = ";",
                      dec = ".")

```

###### ^1^ click: [Alcohol Consumption](https://www.kaggle.com/sansuthi/alcohol-consumption)

1.[file] view 

```{r}
View(dfAlc)
```

1.[file] check structure

```{r}
str(dfAlc)
```

1.[table] create frequency table for factor

```{r}
tableAlcCountry <- c(dfAlc$abbrv)
table(tableAlcCountry)
```

1.[vector] create 

```{r}
country<- c("Afghanistan","Albania","Algeria","Andorra","Angola", "Antigua and Barbuda")
country
abbrv <- c("AF", "AL", "DZ", "AD", "AO", "AG")
abbrv
aconsum <- c(0, 7, 1, 10, 6, 8)
aconsum
x <- c(60,50 ,40, 30, 20)
x
```

1.[vector] change elements' type 

```{r}
y<- as.character(x) 
y
as.numeric(y)
x<-y
```

1.[vector]check default type 

```{r}
x<-c(1,"test",3)
x
class(x)
```

1.[vector]check default type 

```{r}
x<-c("1","test","3")
x
class(x)
as.numeric(x)
```

###### ^1^ Note: coercion problem -> NAs introduced by coercion 

1.[vector] sort elements' values in increasing order 

```{r}
sort(x) 
```

1. [vector] return/keep index of the elements' values in increasing order

```{r}
index <- order(x)
index
```

1.[vector] sort vector's elements in order, through indexing

```{r}
x[index]
```

1.[vector] check order 

```{r}
order(x)
```

1.[vector] rank; returns the order of each element in an ascending list

```{r}
rank(x)
```

1.{vector} associate 

```{r}
abbrvCountry <- c("AF"="Afghanistan", "AL" = "Albania", "DZ" ="Algeria", "AD" = "Andorra", "AO" = "Angola", "AG"= "Antigua and Barbuda")
abbrvCountry
```

1.[vector] assign name

```{r}
names(abbrvCountry)<-abbrv 
abbrv
abbrvCountry
```

1.[vector] access vector's element's value descreately, through indexing 

```{r}
abbrvCountry[2]
```

1.[vector] access vector's elements' values descreately, through indexing

```{r}
abbrvCountry[c(1,3)]
```

1.[vector] access vector's elements' values interval-ly, through indexing 

```{r}
abbrvCountry[1:2]
```

1.[vector] access vector's elements' values interval-ly, through naming the element  

```{r}
abbrvCountry["AF"]
abbrvCountry[c("AL","DZ")]
```

1.[dataFrame] create data frame

```{r}
dfAbbrvAconsum <- data.frame(country = abbrv, alchoholconsumption = aconsum)
```

1.[file] check class

```{r}
class(dfAlc)
class(dfAlc$aconsum)
```

1.[element] change type of element 

```{r}
class(1)
class(1L)
```

1.[sequence] show

```{r}
seq(1,10)
1:10
```

1.[sequence] generate increasing sequence of numbers with pretermed length

```{r}
seq(1, 10, length.out = 100)
```


1.[sequence] check length

```{r}
length(seq(1,10))
```


1.[dataFrame] check levels of a factor

```{r}
levels(dfAlc$aconsum)
```

1.[dataFrame] check number of levels of a factor

```{r}
nlevels(dfAlc$aconsum)
```

1.[file] check headers

```{r}
head(dfAlc)
```
1.[file] check headers' names

```{r}
names(dfAlc)
```

1.[file] exact name 

```{r}
colnames(dfPonzo)
```

1.[file] rename exact name column

```{r}
colnames(dfPonzo)[colnames(dfPonzo) == 'X.Gaze.x...'] <- 'xGaze'
colnames(dfPonzo)[colnames(dfPonzo) == 'X.Gaze.y...'] <- 'yGaze'
colnames(dfPonzo)[colnames(dfPonzo) == 'X..RespondentNr.'] <- 'respondentNr'
colnames(dfPonzo)[colnames(dfPonzo) == 'X.StimulusNr.'] <- 'stimulusNr'
colnames(dfPonzo)[colnames(dfPonzo) == 'X.timestamp.ms.'] <- 'timeStampsMs'
```

1.[row-column] access value

```{r}
dfPonzo[12,3]
```

1.[column-row] access value

```{r}
dfAlc$country[11]
```


1.[column] access

```{r}
dfAlc["aconsum"]
```

1.[vector]sort in increasing order 

```{r}
sort(dfAlc$aconsum)
```


1.[column] access through vector

```{r}
dfAlc[["aconsum"]]
```


1.[column] access through vector

```{r}
dfAlc$aconsum
```

1.[object] define

```{r}
aconsum <- dfAlc$aconsum
urbanrt <-dfAlc$urbanrt
employrt <- dfAlc$employrt
```

1.[vector] count NAs

```{r}
naS <- is.na(aconsum)
sum(naS)
```

1.[vector] expell NAs

```{r}
mean(aconsum[!naS])
```

1.[vector] point column from data frame to calculate the mean for

```{r}
mean(dfAlc[,2])
```


1.[object] define length

```{r}
length(aconsum)
```

1.[vector] return number of elements

```{r}
lengthAconsum <- length(dfAlc$aconsum)
lengthAconsum
```

1.[object] check identical

```{r}
identical(urbanrt,employrt)
```

1.[vector] return index of the elements' values in increasing order 

1.1.[vector] sort vector's elements in order, through indexing

```{r}
iOrdDfAconsum<-order(dfAlc$aconsum)
dfAlc$abbrv[iOrdDfAconsum]
```

1.[vector] find max value between elements, through indexing

1.1[object] return index

1.1.1[vector] show value of element, through indexing the object 

```{r}
iMax<-which.max(dfAlc$aconsum)
iMax
dfAlc$abbrv[iMax]
dfAlc$abbrv[which.max(dfAlc$aconsum)]
```

1.[vector] find max value between elements, through indexing

1.1[object] return index

1.1.1[vector] show value of element, through indexing the object 

```{r}
iMin<-which.max(dfAlc$aconsum)
iMin
dfAlc$abbrv[iMin]
dfAlc$abbrv[which.min(dfAlc$aconsum)]
```

1.[vector] order

```{r}
dfAlc$abbrv[order(dfAlc$employrt,decreasing=TRUE)]
```

1.[vector] check range through indexing

1.1.[vector] count the number of elements in the range

```{r}
i <- dfAlc$aconsum  < 5
i
dfAlc$abbrv[i]
sum(i,na.rm =TRUE)
```

1.1.[vector] filter data by sub-setting row

```{r}
filter(dfAlc, region=="EMEA")
```

1.[vector] filter

```{r}
emea<- dfAlc$region == "EMEA" 
aconsum <- dfAlc$aconsum <= 5 
i <- aconsum&emea
dfAlc$abbrv[i]
```

1.1.[vector] which indexes of elements  has value TRUE 

```{r}
which(i)
```

1.1.[vector] which value TRUE or FALSE of element 

```{r}
i<-which(dfAlc$abbrv == "BG")
i
aconsum[i]
```

1.1.[vector] match values of elements and return TRUE or FALSE 

```{r}
i <- match(c("BG","IT","ES"),dfAlc$abbrv)
i
dfAlc$abbrv[i]
aconsum[i]
```

1.1.[vector] check whether values of vector in values of vector and return TRUE or FALSE 

```{r}
emea<- dfAlc$region == "EMEA" 
aconsum5 <- dfAlc$aconsum <= 5 
aconsum10 <- dfAlc$aconsum <= 5 
aconsum5&emea %in% aconsum10&emea
```

1.1.[vector] check whether each value of vector in values of the same vector and return TRUE or FALSE 

```{r}
checkAbbrv<- c("GB","BG","MZ") %in% dfAlc$abbrv
```

1.1.[vector] check whether each value of vector in values of the same vector, through indexing and return TRUE or FALSE 

```{r}
checkAbbrv<- c("GB","BG","MZ") %in% dfAlc$abbrv
i <- which(!checkAbbrv%in%dfAlc$abbrv)
i
checkAbbrv[i] 
```

1.1.[dataFrame] mutate data frame

```{r}
dfAlc <- mutate(dfAlc,rank=rank(-dfAlc$aconsum))
str(dfAlc)
```
###### ^2^ Note: include a column named rank with the ranks of rate from highest to lowest

1.1.[dataFrame] excluding filter value and create data frame 

```{r}
dfNoEMEA <- data.frame(filter(dfAlc,region!="EMEA"))
nrow(dfNoEMEA)
```

1.1.[dataFrame] including filter value and create data frame 

```{r}
dfEMEAAPAC <- data.frame(filter(dfAlc,region %in% c("EMEA","APAC")))
nrow(dfEMEAAPAC)
```

1.1.[dataFrame] filter and select only

```{r}
EMEAAPACAconsum10 <- filter(dfAlc,region %in% c("EMEA","APAC") & aconsum < 10)
dplyr::select(EMEAAPACAconsum10,country,aconsum,rank)
```

1.1.[dataFrame] select subsetting and filter 

```{r}
newTable <- dplyr::select(dfAlc,country,region,aconsum) 
filter(newTable,aconsum <= 10)
str(newTable)
```
1.[dataFrame] pipe select and pipe filter

```{r}
dfAlc %>% dplyr::select(country,region,aconsum) %>% filter(aconsum <= 10)
```

1.[dataFrame] filter pipe select

```{r}
filter(dfAlc, region %in% c("EMEA", "APAC") & aconsum < 10 )%>% dplyr::select(country, aconsum, rank)
```
1.[dataFrame] pipe filter select
```{r}
dfAlc %>% mutate(aconsum, rank) %>% filter(region %in% c('EMEA','APAC') & aconsum <10) %>% dplyr::select(country,aconsum,rank)
```

1.[dataFrame]

```{r}
ind <- heights$height > mean(heights$height)#How many individuals in the dataset are above average height?
sum(ind)
ind <- heights$height > mean(heights$height) & (heights$sex =="Female")#How many individuals in the dataset are above average height and are female?
sum(ind)
mean(heights$sex == "Female")# proportion of individuals in the dataset are female
minH<- min(heights$height) 
ind <- match(minH, heights$height)#Use the match() function to determine the index of the first individual with the minimum height.
heights$sex[ind]#Subset the sex column of the dataset by the index in 4b to determine the individualâ€™s sex.
maxH <- max(heights$height)#Write code to create a vector x that includes the integers between the minimum and maximum heights (as numbers).
minH <- min(heights$height)
intgr <- c(minH:maxH)
intgr
sum(!(intgr %in% heights$height))#How many of the integers in x are NOT heights in the dataset?
heights <- mutate(heights, ht_cm = height*2.54)#create a new column of heights in centimeters named ht_cm
head(heights)
heights$ht_cm[18]
mean(heights$ht_cm) 
females <- filter(heights, sex == "Female") #females by filtering the heights2 data to contain only female individuals.
head(females)
nrow(females)#How many females are in the heights2 dataset?
mean(females$ht_cm)#What is the mean height of the females in centimeters?
```

3.[if-els] 

```{r}
i <- which.min(dfAlc$aconsum)
if (dfAlc$aconsum[i] < 10){
  print(dfAlc$country[i])
}else{
  print("No coutnry has alcochol rate that low")
}
```

3.[ifelse] if logical is TRUE, then return 1st answer, if FALSE, then 2nd answer

```{r}
minAlc <- which.min(dfAlc$aconsum)
ifelse(minAlc,dfAlc$country,NA)
```

2.[dataFrame]remove NA

```{r}
sum(is.na(dfAlc))
dfAlc[is.na(dfAlc)] = 0
View(dfAlc)
```

3.[ifelse][all]

```{r}
if(all(dfAlc$aconsum < 30)){
  print("World Alcochol rate is under 30")
} else{
  print("World Alcochol rate is not under 30")
}
```

3.[ifelse]

```{r}
str(dfAlc)
x <- dfAlc$country
xCharCountry <- nchar(x)
y <- dfAlc$abbrv
changeCountryToAbbrv<- ifelse(xCharCountry >2,y,x)
changeCountryToAbbrv
```

3.[any] take a vector of logicals ; return true, if any of the entries is true 

```{r}
x <- c(TRUE, FALSE)
any(x)
```

3.[all] take a vector of logicals; return  TRUE, if all the entries are true 

```{r}
x <- c(TRUE, FALSE)
all(x)
```

4.[function]

```{r}
avg <- function(x){
  s <- sum(x)
  n <- length(x)# Note:  not saved in the work space; the values of the variables are changed only during the F's call
  s/n
} 
x<- dfAlc$urbanrt
identical (mean(x),avg(x))
```

4.[function]

```{r}
avg <- function(x,arithmetic=TRUE){ # calculate either geometric, or arithmetic average depending on predefined variable
    n <- length(x)
    arithmetic <-sum(x)/n
    geometric<- prod(x)^(1/n)
    ifelse(arithmetic,arithmetic,geometric)
  }
x<- dfAlc$urbanrt
avg(x)
```

3.[forloop]

```{r}
compute_s_n <- function(n){
    x<- 1:n
    sum(x) 
  }
compute_s_n(3)
m <-25 
s_n <- vector(length = m)#create an empty vector for storing
for(n in 1:m){
  s_n[n] <- compute_s_n(n)
}
n <- 1:m
plot(n,s_n)
lines(n,n*(n+1)/2)
```

3.[forloop]

```{r}
sum <- 0
for(i in 1:2) 
  sum <- sum + i^2
sum
```


2.[ggplot]

```{r}
abbCountry <- dfAlc$abbrv 
suicidesPer100 <- dfAlc$suicideper100
urbanRT <- dfAlc$urbanrt
region <- dfAlc$region
ranksAConsumption <- rank(dfAlc$aconsum,na.last = NA)
i <- order(dfAlc$aconsum)
df<- data.frame(country = abbCountry[i], suicide = suicidesPer100[i], rank = ranksAConsumption[i],urbanrate = urbanRT[i],region = region[i])
df %>%
  ggplot(aes(urbanrate, suicide, label=country,color=rank)) + geom_label()

```

2.[ggplot]

```{r echo=TRUE, message=FALSE, warning=FALSE}
dfAlc %>%
  ggplot(aes(urbanrt, employrt, label=abbrv, color=region)) + geom_label()
```

2.[ggplot]

```{r echo=TRUE, message=FALSE, warning=FALSE}
dfAlc %>%
  ggplot(aes(urbanrt, employrt, label=abbrv, color=region)) + geom_label()
```

2.[scatterPlot]

```{r}
plot(dfAlc$suicideper100,dfAlc$aconsum, xlab = "suicides/100 people", ylab="alcohol consumption")
plot(dfAlc$employrt,dfAlc$aconsum, xlab = "employee rate", ylab="alcohol consumption")
plot(dfAlc$urbanrt,dfAlc$aconsum, xlab = "urban rate", ylab="alcohol consumption")
```

2.[scatterPlot] in logs

```{r}
log10IncomePer1 <- log10(dfAlc$incomeper1)
log10Aconsum <- log10(dfAlc$aconsum)
plot(log10IncomePer1,log10Aconsum)
```

2.[histogram]

```{r}
hist(dfAlc$aconsum,xlab = "alcohol consumption") 
dfAlc$country[which.max(dfAlc$aconsum)]
```

2.[boxplot]

```{r}
boxplot(aconsum~region, data = dfAlc,na.action = NULL) 
boxplot(suicidesPer100~region, data = dfAlc)
boxplot(employrt~region, data = dfAlc)
boxplot(urbanrt~region, data = dfAlc)
```


## II.

## Libraries

> library load 

```{r}
library(UsingR)
```

1.[dataFrame]filter

```{r}
controlsXGaze <- filter(dfPonzo, stimulusNr == c(1,3,13,15,25,27)) %>% dplyr::select(xGaze) %>% summarise(mean(xGaze))
controlsXGaze
controlsYGaze <-filter(dfPonzo, stimulusNr == c(1,3,13,15,25,27)) %>% dplyr::select(yGaze) %>% summarise(mean(yGaze))
controlsYGaze
```

1.[dataFrame] pipe filter select unlist

```{r}
controlsXGaze <- filter(dfPonzo, stimulusNr == c(1,3,13,15,25,27)) %>% dplyr::select(xGaze) 
mean(controlsXGaze$xGaze)
controlsYGaze <-filter(dfPonzo, stimulusNr == c(1,3,13,15,25,27)) %>% dplyr::select(yGaze)
mean(controlsYGaze$yGaze)
longUpXGaze  <-filter(dfPonzo, stimulusNr == c(5,7,17,19,29,31))%>% dplyr::select(xGaze)
mean(longUpXGaze$xGaze)
longUpYGaze  <-filter(dfPonzo, stimulusNr == c(5,7,17,19,29,31))%>% dplyr::select(yGaze)
mean(longUpYGaze$yGaze)
longDownXGaze<- filter(dfPonzo, stimulusNr == c(9,11,21,23,33,35))%>% dplyr::select(xGaze)
mean(longDownXGaze$xGaze)
longDownYGaze<- filter(dfPonzo, stimulusNr == c(9,11,21,23,33,35))%>% dplyr::select(yGaze)
mean(longDownYGaze$yGaze)
```

1.[dataFrame] filter select

```{r}
controls <- filter(dfPonzo, stimulusNr == c(1,3,13,15,25,27)) 
head(controls)
View(controls)
mean(controls$xGaze)
mean(controls$yGaze)
longUp  <-filter(dfPonzo, stimulusNr == c(5,7,17,19,29,31))
head(longUp)
View(longUp)
mean(longUp$xGaze)
mean(longUp$yGaze)
longDown <- filter(dfPonzo, stimulusNr == c(9,11,21,23,33,35))
head(longDown)
View(longDown)
mean(longDown$xGaze)
mean(longDown$yGaze)
```

1.[dataFrame] turn into numeric vector

```{r}
unlist(controls)
unlist(longUp)
unlist(longDown)
```

3.[plot]

```{r}
plot(controls$xGaze,controls$yGaze,xlab = "controlsXGaze", ylab="controlsYGaze") 
plot(longUp$xGaze,longUp$yGaze,xlab = "longUpXGaze", ylab="longUpYGaze") 
plot(longDown$xGaze,longDown$yGaze,xlab = "longDownXGaze", ylab="longDownYGaze") 
```

1.[population]get different random sample of 12;random variable of random sample

```{r}
popDfPonzoXGaze <- unlist(dfPonzo$xGaze)
popDfPonzoYGaze <- unlist(dfPonzo$yGaze)
mean(sample(popDfPonzoXGaze,12))
mean(sample(popDfPonzoYGaze,12))
mean(popDfPonzoXGaze)
mean(popDfPonzoYGaze)
```

1.[seed] set/ produce the same sample again and again = generate same set at each time

```{r}
set.seed(1) 
```

1.[average] difference between the average of the sample and the average of the pop

```{r}
sampleDfPonzoXGaze<- sample(popDfPonzoXGaze,5)
abs(mean(sampleDfPonzoXGaze)-mean(popDfPonzoXGaze))
sampleDfPonzoYGaze<- sample(popDfPonzoYGaze,5)
abs(mean(sampleDfPonzoYGaze)-mean(popDfPonzoYGaze))
```

1.[seed] set/ produce the same sample again and again = generate same set at each time by setting the starting number used to generate a sequence of random numbers

```{r}
set.seed(5) 
```

1.[average] difference between the average of the sample and the average of the pop

```{r}
sampleDfPonzoXGaze<- sample(popDfPonzoXGaze,5)
abs(mean(sampleDfPonzoXGaze)-mean(popDfPonzoXGaze))
sampleDfPonzoYGaze<- sample(popDfPonzoYGaze,5)
abs(mean(sampleDfPonzoYGaze)-mean(popDfPonzoYGaze))
```

###### ^1^ Note: the average of the samples is a random variable =>inferential statistics needed

1.[nullDistribution] all possible realizations under the null 

```{r}
obslongUpControlsX <- mean(longUp$xGaze) - mean(controls$xGaze)
obslongUpControlsY <- mean(longUp$yGaze) - mean(controls$yGaze)
obslongDownControls <- mean(longDown$xGaze) - mean(controls$xGaze)
obslongDownControls <- mean(longDown$yGaze) - mean(controls$yGaze)
popDfPonzoXGaze <- unlist(dfPonzo$xGaze)
popDfPonzoXGaze <- unlist(dfPonzo$yGaze)
popDfPonzoControls <- sample(popDfPonzoXGaze,12)
popDfPonzoLongUp <- sample(popDfPonzoXGaze,12)
mean(popDfPonzoLongUp) - mean(popDfPonzoControls)
popDfPonzoControlsY <- sample(popDfPonzoYGaze,12)
popDfPonzoLongUpY <- sample(popDfPonzoYGaze,12)
mean(popDfPonzoLongUpY) - mean(popDfPonzoControlsY)
```

###### ^1^ Note: do sampling and substraction multiple times = see several realizations of the difference in mean  for the null hypothesis

1.[nullHypothesis] check 

```{r}
n<-10000
nullsPopX <- vector("numeric",n)
for(i in 1:n){
  popDfPonzoControlsX <- sample(popDfPonzoXGaze,12)
  popDfPonzoLongUpX <- sample(popDfPonzoXGaze,12)
  nullsPopX[i]<- mean(popDfPonzoLongUpX) - mean(popDfPonzoControlsX)
}
max(nullsPopX)
hist(nullsPopX)
```

```{r}
n<-10000
nullsPopY <- vector("numeric",n)
for(i in 1:n){
  popDfPonzoControlsY <- sample(popDfPonzoYGaze,12)
  popDfPonzoLongUpY <- sample(popDfPonzoYGaze,12)
  nullsPopY[i]<- mean(popDfPonzoLongUpY) - mean(popDfPonzoControlsY)
}
max(nullsPopY)
hist(nullsPopY)
```

###### ^1^ Note: if knowing the null distribution, one can describe the proportion of values one sees for any interval of values -> define a number of times to redo the null hypothesis check; record all differences  

1.[nullHypothesis] #1 option: how often (frequency) null values are bigger or not than observed values 
```{r}
sum(nullsPopX > obslongUpControlsX)/n 
sum(nullsPopY > obslongUpControlsY)/n 
```

1.[nullHypothesis] #2 option: proportion of times the null is bigger than the observation 

```{r}
mean(nullsPopX > obslongUpControlsX)
mean(nullsPopY > obslongUpControlsY)
```

1.[pValue] probability that an outcome from the null distribution is bigger than what one observed when the null hypothesis is true 

```{r}
mean(abs(nullsPopX) >obslongUpControlsX)
mean(abs(nullsPopY) >obslongUpControlsY)
```

###### ^1^ Note: #3 option: how often (frequency) it is bigger in absolute 

1.[nullDistribution] loop for 1000 times taking a random sample of 5 gazes calculating the mean and storing it within an averages vector 

```{r}
head(popDfPonzoXGaze)
set.seed(1)
n<-1000
averagesPopX <- vector("numeric",n)
for(i in 1:n){
  X <- sample(popDfPonzoXGaze,5)#using a for-loop take a random sample of 5 gazes 1,000 times ; save these averages
  averagesPopX[i]<- mean(X)
}
```

```{r}
hist(averagesPopX)
```

1.[nullHypothesis] check 

```{r}
mean( abs( averagesPopX - mean(popDfPonzoXGaze) ) > 0.05) #What proportion of these 1,000 averages are more than 0.05%  away from the average of mean(X) ?
```

1.[nullDistribution] loop for 10000 times taking a random sample of 5 gazes calculating the mean and storing it within an averages vector 

```{r}
head(popDfPonzoXGaze)
set.seed(1)
n<-10000
averagesPopX <- vector("numeric",n)
for(i in 1:n){
  X <- sample(popDfPonzoXGaze,5)#using a for-loop take a random sample of 5 gazes 10000 times ; save these averages
  averagesPopX[i]<- mean(X)
}
```

```{r}
hist(averagesPopX)
```

1.[nullHypothesis] check 

```{r}
mean( abs( averagesPopX - mean(popDfPonzoXGaze) ) > 0.05) #What proportion of these 10000 averages are more than 0.05%  away from the average of mean(X) ?
```

1.[nullDistribution] loop for 10000 times taking a random sample of 5 gazes calculating the mean and storing it within an averages vector 

```{r}
head(popDfPonzoYGaze)
set.seed(1)
n<-1000
averagesPopY <- vector("numeric",n)
for(i in 1:n){
  Y <- sample(popDfPonzoYGaze,5)#using a for-loop take a random sample of 5 gazes 1,000 times ; save these averages
  averagesPopY[i]<- mean(Y)
}
```

```{r}
hist(averagesPopY)
```

1.[nullHypothesis] check 

```{r}
mean( abs( averagesPopY - mean(popDfPonzoYGaze) ) > 0.05)#What proportion of these 1,000 averages are more than 0.05%  away from the average of mean(Y) ?
```

1.[normalApproximation] describe distribution = describe the entier list

```{r}
head(popDfPonzoXGaze)
mean(popDfPonzoXGaze <= 0.500)
prop = function(q) {
  mean(popDfPonzoXGaze <= q)
}
qs<- seq(from = min(popDfPonzoXGaze), to = max(popDfPonzoXGaze), length=20)
props = sapply(qs,prop)
props = sapply(qs, function(q) mean(popDfPonzoXGaze <= q))
```

1.[normalApproximation] plot

```{r}
plot(qs, props)
```

###### ^1^ Note: #1 option: empirical cumulative distribution function 

1.[normalApproximation] describe distribution = describe the entier list => empirical cumulative distribution function 

```{r}
plot(ecdf(popDfPonzoXGaze))
```

###### ^1^ Note: #2 option: empirical cumulative distribution function 


1.[centralLimitTheorem] 

```{r}
head(popDfPonzoXGaze)
set.seed(1)
n<-1000
averagesPopX5 <- vector("numeric",n)
for(i in 1:n){
  X <- sample(popDfPonzoXGaze,5)#using a for-loop take a random sample of 5 mice 1,000 times ; Save these averages
  averagesPopX5[i]<- mean(X)
}
```

```{r}
head(popDfPonzoXGaze)
set.seed(1)
n<-1000
averagesPopX50 <- vector("numeric",n)
for(i in 1:n){
  X <- sample(popDfPonzoXGaze,50)#using a for-loop take a random sample of 5 mice 1,000 times ; Save these averages
  averagesPopX50[i]<- mean(X)
}
```

```{r}
par(mfrow = c(2,1))
hist(averagesPopX5)
hist(averagesPopX50)  
```

```{r}
mean(averagesPopX5<0.600 & averagesPopX5>0.400)
mean(averagesPopX50<0.600 & averagesPopX50>0.400)
```

###### ^1^ Note: for the last set of averages, the ones obtained from a sample size of 5 vs. 50, what proportion are between 0.400 and 0.600? 

```{r}
mu <- mean(averagesPopX50)
mu
sigma <- sd(averagesPopX50)
sigma
```

1. [pNorm] find  proportion of observations below a cutoff x given a normal distribution with mean mu and standard deviation sigma with pnorm(x, mu, sigma) or pnorm( (x-mu)/sigma )

```{r}
pnorm(0.600, mu, sigma) - pnorm(0.400,mu,sigma)  
```

###### ^1^ Note: What is the proportion of observations between 0.600 and 0.400 in a normal distribution with mu and sd?

1.[centralLimitTheorem]

```{r}
popMean <- mean(popDfPonzoXGaze)
popSD <- sd(popDfPonzoXGaze)
propWithinOneSDX<- (popDfPonzoXGaze-popMean)/popSD
mean(abs(propWithinOneSDX) <=1) #What proportion of xGaze% are within 1 SD away from the average Gaze%?
mean(abs(propWithinOneSDX) <=2)#What proportion of xGaze% are within 2 SD away from the average Gaze%?
mean(abs(propWithinOneSDX) <=3) #What proportion of xGaze% are within 3 SD away from the average Gaze%?
popMean <- mean(popDfPonzoYGaze)
popSD <- sd(popDfPonzoYGaze)
propWithinOneSDY<- (popDfPonzoYGaze-popMean)/popSD
mean(abs(propWithinOneSDY) <=1) #What proportion of xGaze% are within 1 SD away from the average Gaze%?
mean(abs(propWithinOneSDY) <=2)#What proportion of xGaze% are within 2 SD away from the average Gaze%?
mean(abs(propWithinOneSDY) <=3) #What proportion of xGaze% are within 3 SD away from the average Gaze%?
```

> library load 

```{r}
library(rafalib)
```

```{r}
qqnorm(popDfPonzoXGaze)
abline(0,1)
qqnorm(popDfPonzoYGaze)
abline(0,1)
```

> library load 

```{r}
library(dplyr)
```

```{r}
avgs <- replicate(10000, mean( sample(popDfPonzoXGaze, 25)))
mypar(1,2)
hist(avgs)
qqnorm(avgs)
qqline(avgs)
mean(avgs) #What is the average of the distribution of the sample average?
```

> library load 

```{r}
library(rafalib)
```

```{r}
sd(avgs)#What is the standard deviation of the distribution of sample averages (use popsd())?
```

> library load 

```{r}
library(dplyr)
```

1.[centralLimitTheorem] practice

###### ^1^ Note: the NUll distirbution is very well approximated by a normal distribution; checkwhether normal approximation applies

```{r}
obslongUpControlsX <- mean(longUp$xGaze) - mean(controls$xGaze)
obslongUpControlsY <- mean(longUp$yGaze) - mean(controls$yGaze)
popDfPonzoXGaze <- unlist(dfPonzo$xGaze)
popDfPonzoYGaze <- unlist(dfPonzo$yGaze)
```

```{r}
popDfPonzoControlsX <- sample(popDfPonzoXGaze,12)
popDfPonzoLongUpX <- sample(popDfPonzoXGaze,12)
mean(popDfPonzoLongUpX) - mean(popDfPonzoControlsX)#random sample;get different random sample of 12;random variable of random sample
popDfPonzoControlsY <- sample(popDfPonzoYGaze,12)
popDfPonzoLongUpY <- sample(popDfPonzoYGaze,12)
mean(popDfPonzoLongUpY) - mean(popDfPonzoControlsY)
```

###### ^1^ Note: if knowing the null distribution, one can describe the proportion of values one sees for any interval of values 
###### ^1^ Note: define a number of times to redo the null hypothesis check; record all differences

```{r}
n<-10000
nullsPopX <- vector("numeric",n)
for(i in 1:n){
  popDfPonzoControlsX <- sample(popDfPonzoXGaze,12)
  popDfPonzoLongUpX <- sample(popDfPonzoXGaze,12)
  nullsPopX[i]<- mean(popDfPonzoLongUpX) - mean(popDfPonzoControlsX)
}
max(nullsPopX)
hist(nullsPopX)
```
```{r}
n<-10000
nullsPopY <- vector("numeric",n)
for(i in 1:n){
  popDfPonzoControlsY <- sample(popDfPonzoYGaze,12)
  popDfPonzoLongUpY <- sample(popDfPonzoYGaze,12)
  nullsPopY[i]<- mean(popDfPonzoLongUpY) - mean(popDfPonzoControlsY)
}
max(nullsPopY)
hist(nullsPopY)
```

1.[nullHypothesis]

```{r}
sum(nullsPopX > obslongUpControlsX)/n #1 option: how often null values are bigger or not than observed values 
sum(nullsPopY > obslongUpControlsY)/n 
```

```{r}
mean(nullsPopX >obslongUpControlsX) #2 option: proportion of times the null is bigger than the observation 
mean(nullsPopY >obslongUpControlsY)
```

```{r}
mean(abs(nullsPopX) >obslongUpControlsX)#3 option: how often it is bigger in absolute 
mean(abs(nullsPopY) >obslongUpControlsY)
```

###### ^1^ Note: p value = the probability that an outcome from the null distribution is bigger than what one observed when the null hypothesis is true 

> library load 

```{r}
library(rafalib)
```

```{r}
mypar()
qqnorm(nullsPopX)
qqline(nullsPopX)
qqnorm(nullsPopY)
qqline(nullsPopY)
```
###### ^1^ Note: use normal approximation instead of accessing the population through changes of the sample 

> library load 

```{r}
library(dplyr)
```

1.[tTest]

```{r}
N <- length(controlsXGaze)
se <- sqrt(var(longUpXGaze)/N+ #square root of the variance of the sample estimate of the variance divided by N=sample size
               var(controlsXGaze)/N) #gives us standard error estimate
tstatX <- obslongUpControlsX/se
tstatX
library(dplyr)
N <- length(controlsYGaze)
se <- sqrt(var(longUpYGaze)/N+ 
             var(controlsYGaze)/N) 
tstatY <- obslongUpControlsY/se
tstatY
```

```{r}
1- pnorm(tstatX) #what proportion of normally distributed data, with means 0 and standard deviation 1,are lower than whatever value you put here
2*(1- pnorm(tstatX))
1- pnorm(tstatY) 
2*(1- pnorm(tstatY))
```

```{r}
n<-10000
nullsPopX <- vector("numeric",n)
for(i in 1:n){
  popDfPonzoControlsX <- sample(popDfPonzoXGaze,12)
  popDfPonzoLongUpX <- sample(popDfPonzoXGaze,12)
  nullsPopX[i]<- mean(popDfPonzoLongUpX) - mean(popDfPonzoControlsX)
}

n<-10000
nullsPopY <- vector("numeric",n)
for(i in 1:n){
  popDfPonzoControlsY <- sample(popDfPonzoYGaze,12)
  popDfPonzoLongUpY <- sample(popDfPonzoYGaze,12)
  nullsPopY[i]<- mean(popDfPonzoLongUpY) - mean(popDfPonzoControlsY)
}
```

###### ^1^ Note: how good of an approximation this is => access the population 

> library load 

```{r}
library(rafalib)
```

```{r}
mypar()
qqnorm(nullsPopX)
abline(0,1)
qqline(nullsPopX)
qqnorm(nullsPopY)
abline(0,1)
qqline(nullsPopY)
```


## III.

1.[vector] discrete numeric data  considered ordinal-ly 

```{r}
unique(dfAlc$employrt)
length(unique(dfAlc$employrt))
```

1.[vector] compute the frequencies of each unique value 

```{r}
table(dfAlc$employrt)
prop.table(table(dfAlc$region))
```

1.[vector] sum frequencies 

```{r}
sum(table(dfAlc$employrt)==1)
```

> load library

```{r}
library(dplyr)
```

1.[column] remove NAs 

```{r}
dfAlc[is.na(x = dfAlc)] <- 0
```

1.[CDF] cumulative distribution function for continuous data 

```{r}
rangeForCdfFunction <- seq(min(dfAlc$employrt), max(dfAlc$employrt),length = 100) #define range of values spanning the dataset 
cdfFunction <- function(f){ # computes probability for a single value
  mean(dfAlc$employrt<=f) # cdfFunction (rangeForCdfFunction) = Pr (f</=rangeForCdfFunction) 
}
cdfValuesBelow <- sapply(rangeForCdfFunction,cdfFunction)#  CDF defines proportion of data below the  cutoff rangeForCdfFunction
cdfValuesAbove <- 1-(sapply(rangeForCdfFunction,cdfFunction)) # defines proportion of data above the  cutoff rangeForCdfFunction => 1 - cdfFunction (rangeForCdfFunction)
```

3.[plot] CDF 

```{r}
plot(rangeForCdfFunction,cdfValuesBelow)
EmployeeRate <- rangeForCdfFunction
Proportion<- cdfValuesBelow
plot(EmployeeRate,Proportion)
plot(rangeForCdfFunction,cdfValuesAbove) 
```

```{r}
rangeForCdfFunctionQ <- seq(quantile(dfAlc$employrt,0.50), quantile(dfAlc$employrt,0.75),length = 100) 
cdfFunction <- function(f){ 
  mean(dfAlc$employrt<=f)  
}
cdfValuesBellowQ <- sapply(rangeForCdfFunctionQ,cdfFunction) - (sapply(rangeForCdfFunction,cdfFunction)) # define proportion of values between rangeForCdfFunction and rangeForCdfFunctionQ
plot(rangeForCdfFunctionQ,cdfValuesBellowQ)

```

1.[column] mean and standard deviation 

```{r}
meanDfAlcEmpRate <- sum(dfAlc$employrt)/ length(dfAlc$employrt)
sdDfAlcEmpRate <- sqrt(sum((dfAlc$employrt-mean)^2)/ length(dfAlc$employrt))
```

1.[column] filter; access through index; calculate mean and standard deviation 

```{r}
iEMEA <- dfAlc$region == "EMEA" 
xMHeight <- dfAlc$employrt[iEMEA]
mEMEAEmplRt <- mean(xMHeight)
sdEMEAEmplRt <- sd(xMHeight)
c(mEMEAEmplRt=mEMEAEmplRt,sdEMEAEmplRt=sdEMEAEmplRt)
```

1.[mean] within range 

```{r}
mean(xEMEAEmplRt>49 & xEMEAEmplRt<=52)
```

1.[zScore] scale

```{r}
zEMEAEmplRt = scale(xEMEAEmplRt) # converts a vector of approximatley normally distributed values into z-scores
```

1.[zScore] check whether significantly above or below the mean  

```{r}
mean(abs(xEMEAEmplRt)<2)  # compute proportion of observations that are within 2 standard deviations of the mean 
```

1.[pnorm] approximate the proportion of the data without access to actual data 

```{r}
mean(xEMEAEmplRt>49 & xEMEAEmplRt<=52)  
pnorm(72, mean(xEMEAEmplRt),sd(xEMEAEmplRt))- pnorm(69,  mean(xEMEAEmplRt),sd(xEMEAEmplRt)) 
```

###### ^1^ Note:the approximation calculated with the pnorm is very close to the exact calculation with the mean 

1.[pnorm] approximation is not always useful  for the more extreme values - tails

```{r}
exact <- mean(xEMEAEmplRt > 21 & xEMEAEmplRt <= 23) # calculate the proportion of heights between 79 and 81
avg <- mean(xEMEAEmplRt)
sd <- sd(xEMEAEmplRt)
approx <- pnorm(81, avg, sd) - pnorm(79, avg, sd)# estimate the proportion of heights between 79 and 81 
exact/approx # report how many times bigger the actual proportion is compared to the approximation
```


1.[pnorm] mathematically define CDF

```{r}
1 - pnorm(45, mean(xEMEAEmplRt),sd(xEMEAEmplRt)) #whether the probability that a randomly selected employRt is bigger than 45
```

1.[plot] proportion table

```{r}
plot(prop.table(table(xEMEAEmplRt)), xlab = "a = EMEAEmplRt", ylab = "Pr(xEMEAEmplRt = a)")
```

## References

